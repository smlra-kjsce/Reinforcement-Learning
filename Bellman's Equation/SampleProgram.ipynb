{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smlra-kjsce/Reinforcement-Learning/blob/main/Bellman's%20Equation/SampleProgram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOQyr-na2dFc"
      },
      "source": [
        "### **Markov Decision Process (MDP) - Reinforcement Learning with the Q action-value(reward) function.**\n",
        "\n",
        "*Map:*\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1AtI8QdY3pB0f5sWTQWGT178QhwK3jXMJ'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUswTTNN2imD"
      },
      "source": [
        "*R is The Reward Matrix for each state*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tkPb5trL2oAk"
      },
      "outputs": [],
      "source": [
        "import numpy as ql\n",
        "R = ql.matrix([ [0,0,0,0,1,0],\n",
        "\t\t[0,0,0,1,0,1],\n",
        "\t\t[0,0,100,1,0,0],\n",
        "\t\t[0,1,1,0,1,0],\n",
        "\t\t[1,0,0,1,0,0],\n",
        "\t\t[0,1,0,0,0,0] ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfuY9MXL2pyR"
      },
      "source": [
        "*Q is the Learning Matrix in which rewards will be learned/stored*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CPSZnHkB2sf3"
      },
      "outputs": [],
      "source": [
        "Q = ql.matrix(ql.zeros([6,6]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdAlsHaV2ud7"
      },
      "source": [
        "*Gamma :*\n",
        "\n",
        "*It's a form of uncertainty for learning*\n",
        "\n",
        "*If the value is 1 , the rewards would be too high.*\n",
        "\n",
        "*This way the system knows it is learning.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jxNaizHt2xdP"
      },
      "outputs": [],
      "source": [
        "gamma = 0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mUAhRVY2z0C"
      },
      "source": [
        "*s is the state the agent is going from and s' the state it's going to\n",
        "this state can be random or it can be chosen as long as the rest of the choices\n",
        "are not determined.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jbExh2c322D2"
      },
      "outputs": [],
      "source": [
        "agent_s_state = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-WaLX0h233v"
      },
      "source": [
        "*The possible \"a\" actions when the agent is in a given state*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EO40VXzg27HW"
      },
      "outputs": [],
      "source": [
        "def possible_actions(state):\n",
        "    current_state_row = R[state,]\n",
        "    possible_act = ql.where(current_state_row >0)[1]\n",
        "    return possible_act"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sy1Ak729DZ"
      },
      "source": [
        "*Get available actions in the current state*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F1-7z_8O2_HY"
      },
      "outputs": [],
      "source": [
        "PossibleAction = possible_actions(agent_s_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXe0rGzl3A0S"
      },
      "source": [
        "*This function chooses at random which action to be performed within the range \n",
        "of all the available actions.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1DA6O3WF3Et4"
      },
      "outputs": [],
      "source": [
        "def ActionChoice(available_actions_range):\n",
        "    if(sum(PossibleAction)>0):\n",
        "        next_action = int(ql.random.choice(PossibleAction,1))\n",
        "    if(sum(PossibleAction)<=0):\n",
        "        next_action = int(ql.random.choice(5,1))\n",
        "    return next_action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmVnBWYU3Gm9"
      },
      "source": [
        "*Sample next action to be performed*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0d_FTKbz3KGT"
      },
      "outputs": [],
      "source": [
        "action = ActionChoice(PossibleAction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6lAA1sS3Rk9"
      },
      "source": [
        "*Core of the system containing Bellmanâ€™s equation*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "D2VglfDE3OzU"
      },
      "outputs": [],
      "source": [
        "def reward(current_state, action, gamma):\n",
        "    Max_State = ql.where(Q[action,] == ql.max(Q[action,]))[1]\n",
        "\n",
        "    if Max_State.shape[0] > 1:\n",
        "        Max_State = int(ql.random.choice(Max_State, size = 1))\n",
        "    else:\n",
        "        Max_State = int(Max_State)\n",
        "    MaxValue = Q[action, Max_State]\n",
        "    Q[current_state, action] = R[current_state, action] + gamma * MaxValue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdzYiaiT3ZDb"
      },
      "source": [
        "*Rewarding Q matrix*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U2DJ6NTh3cvC"
      },
      "outputs": [],
      "source": [
        "reward(agent_s_state,action,gamma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCN8_wzd3eyl"
      },
      "source": [
        "*Leraning over n iterations just to be sure that the system learns everything there is to find. During each iteration, the agent will detect its present state, choose a course of action, and update the Q function matrix*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "779k5n9y3hGR"
      },
      "outputs": [],
      "source": [
        "for i in range(50000):\n",
        "    current_state = ql.random.randint(0, int(Q.shape[0]))\n",
        "    PossibleAction = possible_actions(current_state)\n",
        "    action = ActionChoice(PossibleAction)\n",
        "    reward(current_state,action,gamma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTHJIM553j-j"
      },
      "source": [
        "*Displaying the learning matrix*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdx-h6-p3mfi",
        "outputId": "33bd78be-1dfe-40fc-b99f-24bdb1b77f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q  :\n",
            "[[  0.      0.      0.      0.    258.44    0.   ]\n",
            " [  0.      0.      0.    321.8     0.    207.752]\n",
            " [  0.      0.    500.    321.8     0.      0.   ]\n",
            " [  0.    258.44  401.      0.    258.44    0.   ]\n",
            " [207.752   0.      0.    321.8     0.      0.   ]\n",
            " [  0.    258.44    0.      0.      0.      0.   ]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Q  :\")\n",
        "print(Q)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}